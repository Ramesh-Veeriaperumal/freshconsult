import groovy.json.*;

node_label = "spot_backend";
backendImage = "792634465463.dkr.ecr.us-east-1.amazonaws.com/freshdesk/backend"
prontoImage = "792634465463.dkr.ecr.us-east-1.amazonaws.com/fworks/pronto:rubcop-0.68.0" // Branch - https://github.com/freshdesk/pronto/tree/fd-branch

isPR = (env.JOB_NAME.contains("pullrequest")) ? true : false
branch = isPR ? params.ghprbSourceBranch : params.BRANCH

workspace_dir = "/home/jenkins/workspace/" + env.JOB_NAME // slave node
checkout_dir = "/home/jenkins/helpkit" // container
containers = ['public': 3, 'private': 5, 'public_w_rollback': 1, 'private_w_rollback': 1 ]

if(env.JOB_NAME.contains("merge")) {
    currentBuild.description = "<a href='${params.commit_url}'>commit_link</a>"
}

timestamps {
    node(node_label) {
        try {
            sh """#!/bin/bash
                eval \$(aws  ecr get-login --no-include-email --region us-east-1)
            """
            cleanup()
            checkout() // checkout helpkit in workspace
            copyConfigFilesFromS3()
            if ( isPR ) { encryptionCheck() } //encryption check for new PRs
            containers.each { container, count ->
                prepareSuite(container, count) // creating test suites for public & private suites
            }
            parallel distributedRun() // running sandbox, public, private - in parallel
            junit testResults: "test/reports/public/**/*.xml,test/reports/private/**/*.xml" // publishing junit report
            archiveArtifacts allowEmptyArchive: true, artifacts: 'test_log/**/*.*'
            publishReport() // publishing coverage html report
            sonarqubeAnalysis() // sonarqube analysis for code coverage
            pushLogsToS3() // tar log directory and pushing to s3
            if (currentBuild.result.equals("UNSTABLE") && isPR) { sendEmail() } // send email if build fails

        } catch (e) {
            currentBuild.result = 'FAILURE'
        } finally {
            // To persist test random failures
            monitJob = env.TEST_MONIT_JOB_NAME
            if (monitJob?.trim()) {
                build job: monitJob,
                wait: false,
                propagate: false,
                parameters: [
                    string(name:'RUN_JOB_NAME', value:env.JOB_NAME),
                    string(name:'RUN_BUILD_NUMBER', value:env.BUILD_NUMBER)
                ]
            }
        }
    }
    // qualityGate() // outside node
}

def distributedRun() {
    def run = [
        'pronto' : { parallel (getCategoryRun('pronto')) },
        'pronto-rails' : { parallel (getCategoryRun('pronto-rails')) }, // Running Custom Rubocop for Rails deprecated methods
//        'sandbox': { parallel (getCategoryRun('sandbox')) },
        'private': { parallel (getCategoryRun('private')) },
        'public' : { parallel (getCategoryRun('public')) },
        'private_w_rollback': { parallel (getCategoryRun('private_w_rollback')) },
        'public_w_rollback' : { parallel (getCategoryRun('public_w_rollback')) }
    ]
    return run;
}

def getCategoryRun(category) {
    def flow = [:]

    if (category.contains('pronto')) {
        flow[category] = {
            stage(category) {
                try {
                    docker.image(prontoImage).inside("--name $category") {
                        println "$category :: container :: " + getContainerID()
                        timeout(time: 60, unit: 'MINUTES') {
                            println "$category :: started :: " + getTimeStamp()
                            sh  """#!/bin/bash
                                cd /home/jenkins/
                                git clone -b $branch git@github.com:freshdesk/helpkit.git
                            """
                            executeTestCase(category)
                            println "$category :: completed :: " + getTimeStamp()
                        }
                    }
                } catch (e) {
                    println "pronto :: exception :: " + e
                }
            }
        }
    } else if (category.equals('sandbox')) {
        flow[category] = {
            stage(category) {
                try {
                    docker.image(backendImage).inside("--name sandbox") {
                        println "sandbox :: container :: " + getContainerID()
                        timeout(time: 60, unit: 'MINUTES') {
                            println "sandbox :: started :: " + getTimeStamp()
                            startServices()
                            println "sandbox :: started services :: " + getTimeStamp()
                            buildSetup(category)
                            println "sandbox :: setup completed :: " + getTimeStamp()
                            executeTestCase(category)
                            println "sandbox :: test completed :: " + getTimeStamp()
                        }
                    }
                } catch (e) {
                    println "Exception :: " + e
                }
            }
        }
    } else if (category.equals('public') || category.equals('private') || category.equals('public_w_rollback') || category.equals('private_w_rollback')) {
        flow[category] = {
            stage(category) {
                def c = [:]
                // splitting tests across multiple containers
                (1..containers[category]).each {
                    c[it] = {
                        def sub_category = category + '_' + it
                        try {
                            docker.image(backendImage).inside("--name $sub_category") {
                                println "$sub_category :: container :: " + getContainerID()

                                timeout(time: 90, unit: 'MINUTES') {
                                    println "$sub_category :: started :: " + getTimeStamp()
                                    exitSuiteIfNotPresent("temp_${sub_category}_suite.rb")
                                    startServices()
                                    println "$sub_category started services :: " + getTimeStamp()
                                    buildSetup(sub_category)
                                    println "$sub_category setup completed :: " + getTimeStamp()
                                    executeTestCase(sub_category)
                                    println "$sub_category :: completed :: " + getTimeStamp()
                                }

                            }
                        } catch (e) {
                            println "$sub_category :: exception :: " + e
                        }
                        println "$sub_category :: docker container removed :: " + getTimeStamp()
                    }
                }
                parallel c
            }
        }
    }
    return flow
}

def getTimeStamp() {
    return new Date().format("dd/MM/YYYY-HH:mm:ss")
}

def killAllExistingContainers() {
    sh "sudo docker stop -t 10 \$(docker ps -a -q) || true"
    sh "sudo docker rm --force \$(docker ps -a -q) || true"
}

def cleanup() {
    cleanWs() // clean workspace
    killAllExistingContainers()
}

def checkout() {
    if (isPR) {
        // if PR > Then merge with target branch before running test
        checkout scm: [
            $class: 'GitSCM',
            branches: [[name: "*/$branch"]],
            doGenerateSubmoduleConfigurations: false,
            extensions: [[
                $class: 'PreBuildMerge',
                options: [mergeRemote: 'origin', mergeTarget: params.ghprbTargetBranch]
            ]],
            submoduleCfg: [],
            userRemoteConfigs: [[
                credentialsId: env.GITHUB_RUNWAYCI_CREDENTIAL_ID,
                url: 'git@github.com:freshdesk/helpkit.git'
            ]]
        ]
    } else {
        checkout scm: [
            $class: 'GitSCM',
            branches: [[name: "*/$branch"]],
            doGenerateSubmoduleConfigurations: false,
            extensions: [],
            submoduleCfg: [],
            userRemoteConfigs: [[
                credentialsId: env.GITHUB_RUNWAYCI_CREDENTIAL_ID,
                url: 'git@github.com:freshdesk/helpkit.git'
            ]]
        ]
    }
    sh "mkdir -p test_log/"
}

def copyConfigFilesFromS3() {
    sh """#!/bin/bash
        aws s3 cp s3://testengineering/Dockerfile-backend/s3.yml config/s3.yml
        aws s3 cp s3://testengineering/Dockerfile-backend/elasticsearch.yml config/elasticsearch.yml
        aws s3 cp s3://testengineering/Dockerfile-backend/redis.yml config/redis.yml
        aws s3 cp s3://testengineering/Dockerfile-backend/channel_api_keys.yml config/channel_api_keys.yml
    """
}

def startServices() {
    sh """#!/bin/bash
        sudo service mysqld start
        sudo service elasticsearch start
        redis-server --port 6379 --daemonize yes
    """
}

def buildSetup(category) {
    sh """#!/bin/bash
        source /etc/profile.d/rvm.sh
        bundle install
        bundle exec rake db:create RAILS_ENV=test
        bundle exec rake db:bootstrap RAILS_ENV=test
    """

    if (category.contains('_w_rollback')) {
        sh """#!/bin/bash
            source /etc/profile.d/rvm.sh
            mysql -u root -e "create database helpkit_test_new_rails3"
            bundle exec rake db:bootstrap_w_clean_setup RAILS_ENV=test
        """
    }

    if (category.equals('sandbox')) {
        println "running additional setup for sandbox"
        sh """#!/bin/bash
            source /etc/profile.d/rvm.sh
            echo "create database sandbox_test" | mysql -u root
            bundle exec rake db:sandbox_shard_setup RAILS_ENV=test
            mkdir tmp/sandbox_test
            git init tmp/sandbox_test/
            git config --global user.email "sample@freshdesk.com"
            git config --global user.name "Sample"
        """
    }
}

def prepareSuite(category, count) {
    docker.image(backendImage).inside("--name prepare_suite") {
        sh """#!/bin/bash
            source /etc/profile.d/rvm.sh
            ruby test/prepare_test_suite.rb $count $category
        """
    }
}

def exitSuiteIfNotPresent(suite) {
    sh """#!/bin/bash
        if [ ! -f test/api/suites/$suite ]; then
            echo "File $suite not exists !"
            exit 1
        fi
    """
}

def executeTestCase(category) {
    try {
        if (category.equals('pronto')) {
            sh """#!/bin/bash
                source /etc/profile.d/rvm.sh
                cd $checkout_dir
                rm -rf Gemfile*
                PRONTO_GITHUB_ACCESS_TOKEN="${env.PRONTO_TOKEN}" PRONTO_PULL_REQUEST_ID=${params.ghprbPullId} pronto run -f github_status github_pr -c origin/falcon-prestaging
            """
        }

        if (category.equals('pronto-rails')) {
            sh """#!/bin/bash
                source /etc/profile.d/rvm.sh
                cd $checkout_dir
                rm -rf Gemfile*
                RUBOCOP_CONFIG='.rubocop_rails.yml'
                export RUBOCOP_CONFIG
                PRONTO_RUBOCOP_TITLE='rubocop_rails'
                export PRONTO_RUBOCOP_TITLE
                PRONTO_GITHUB_ACCESS_TOKEN="${params.PRONTO_TOKEN}" PRONTO_PULL_REQUEST_ID=$params.ghprbPullId pronto run -r=rubocop -f github_status github_pr -c origin/falcon-prestaging
            """
        }

        if (category.contains('public') || category.contains('private')) {
            def tmp_file = "temp_${category}_suite.rb"
            def log_file = "test_log/${category}.log"
            def minitest_report_dir = category.contains('public') ? "test/reports/public/$category" : "test/reports/private/$category"
            def coverage_dir = category.contains('public') ? "tmp/coverage/public" : "tmp/coverage/private"

            sh """#!/bin/bash
                source /etc/profile.d/rvm.sh
                export CODECOV_TOKEN=${env.CODECOV_TOKEN}
                export MINITEST_REPORT_DIR=${minitest_report_dir}
                export COVERAGE_DIR=${coverage_dir}

                echo "============ $category > Suite To Run ============"
                cat test/api/suites/$tmp_file

                bundle exec ruby test/api/suites/$tmp_file >> $log_file
                echo "============ $category > Result ============"
                cat $log_file
                echo "============ $category > Result Ends ============"

                if grep 'Process exited because of the exception' $log_file; then
                    exit 1
                fi
            """
        }

        if (category.equals('sandbox')) {
            def minitest_report_dir = "test/reports/sandbox"
            def coverage_dir = "tmp/coverage/sandbox"

            sh """#!/bin/bash
                source /etc/profile.d/rvm.sh
                export CODECOV_TOKEN=${env.CODECOV_TOKEN}
                export MINITEST_REPORT_DIR=${minitest_report_dir}
                export COVERAGE_DIR=${coverage_dir}

                bundle exec ruby test/api/suites/sandbox_test_suite.rb
            """
        }
    } catch (e) {
        println "$category :: exception in test :: " + getTimeStamp() + " :: " + e
        println "Build UNSTABLE"

        if (category.contains('public') || category.contains('private')) {
            currentBuild.result = 'UNSTABLE'
        }
    }
}

def publishReport() {
    ['public','private'].each {
        publishHTML([
            allowMissing: true,
            alwaysLinkToLastBuild: true,
            keepAll: true,
            reportDir: "tmp/coverage/$it",
            reportFiles: 'index.html',
            reportName: "coverage $it"
        ])
    }
}

def pushLogsToS3() {
    sh """#!/bin/bash
        apt-get install zip -y
        tar -zcvf ${env.JOB_NAME}-${env.BUILD_NUMBER}-logs.tar.gz log
        aws s3 cp ${env.JOB_NAME}-${env.BUILD_NUMBER}-logs.tar.gz s3://jenkins-build-log-store/fdesk/${env.JOB_NAME}-${env.BUILD_NUMBER}-logs.tar.gz --storage-class STANDARD_IA
        echo "https://jenkins-build-log-store.s3.amazonaws.com/fdesk/${env.JOB_NAME}-${env.BUILD_NUMBER}-logs.tar.gz"

        tar -zcvf ${env.JOB_NAME}-${env.BUILD_NUMBER}-test-logs.tar.gz test_log
        aws s3 cp ${env.JOB_NAME}-${env.BUILD_NUMBER}-test-logs.tar.gz s3://jenkins-build-log-store/fdesk/${env.JOB_NAME}-${env.BUILD_NUMBER}-test-logs.tar.gz --storage-class STANDARD_IA
        echo "https://jenkins-build-log-store.s3.amazonaws.com/fdesk/${env.JOB_NAME}-${env.BUILD_NUMBER}-test-logs.tar.gz"
    """
}

def getContainerID() {
    c = sh (
        script: 'set +x && cat /proc/self/cgroup | grep "cpuset:/" | sed "s/\\([0-9]*\\):cpuset:\\/docker\\///g"',
        returnStdout: true
    ).trim()
    return c;
}

def sonarqubeAnalysis() {
    def SONARQUBE_JAVA_HOME = tool 'sonarqube-java'
    def SONARQUBE_SCANNER_HOME = tool 'freshdesk-sonarqube'

    stage('sonnarqube-analysis') {
        try {
            withEnv(["JAVA_HOME=$SONARQUBE_JAVA_HOME", "SONARQUBE_HOME=$SONARQUBE_SCANNER_HOME"]) {
                docker.image(backendImage).inside("--name sonarqube --privileged -v $SONARQUBE_JAVA_HOME:$SONARQUBE_JAVA_HOME -v $SONARQUBE_SCANNER_HOME:$SONARQUBE_SCANNER_HOME") {
                    withCredentials([string(credentialsId: 'SonarqubeGithubToken', variable: 'githubToken')]) {
                        withSonarQubeEnv('FreshdeskSonarqube') {
                            if(isPR){
                                sh  """#!/bin/bash
                                    echo "export LANG='en_US.UTF-8'" >> ~/.profile
                                    echo "export LC_ALL='en_US.UTF-8'" >> ~/.profile
                                    source ~/.profile

                                    $SONARQUBE_HOME/bin/sonar-scanner \
                                        -Dsonar.pullrequest.key=${env.ghprbPullId} \
                                        -Dsonar.pullrequest.branch=${env.ghprbSourceBranch} \
                                        -Dsonar.pullrequest.base=${env.ghprbTargetBranch} \
                                        -Dsonar.github.oauth=$githubToken
                                """
                            } else {
                                commit_url = params.commit_url
                                projectVersion = ((commit_url != null) ? commit_url.split("/").last() : sh(returnStdout: true, script: "git log -n 1 --pretty=format:'%H'")).trim()
                                sh  """#!/bin/bash
                                    echo "export LANG='en_US.UTF-8'" >> ~/.profile
                                    echo "export LC_ALL='en_US.UTF-8'" >> ~/.profile
                                    source ~/.profile

                                    $SONARQUBE_HOME/bin/sonar-scanner \
                                    -Dsonar.branch.name=$branch \
                                    -Dsonar.projectVersion=$projectVersion \
                                    -Dsonar.github.oauth=$githubToken
                                """
                            }
                        }
                    }
                }
            }
        } catch (e) {
            // currentBuild.result = 'UNSTABLE'
            println "sonarqube :: exception :: $e"
        }
    }
}

def qualityGate() {
    stage("quality-gate") {
        timeout(time: 10, unit: 'MINUTES') {
            def qualityGateStatus = waitForQualityGate()
            if (qualityGateStatus.status != 'OK') {
                error "############# Pipeline aborted due to Quality Gate failure: ${qualityGateStatus.status} #############"
            }
        }
    }
}

//encryption check for new PRs
def encryptionCheck() {
    println "encryption check :: " + getTimeStamp()

    docker.image(backendImage).inside("--name encryption_check") {
        sh """#!/bin/bash
            source /etc/profile.d/rvm.sh
            cd /home/jenkins/
            git clone -b $ghprbSourceBranch git@github.com:freshdesk/helpkit.git
            cd helpkit/
            source /etc/profile.d/rvm.sh
            function validate_ejson() {
                git diff --raw $ghprbSourceBranch origin/$ghprbTargetBranch
                for f in \$(git diff --raw $ghprbSourceBranch origin/$ghprbTargetBranch | awk  '{print \$6}' | grep .ejson)
                do
                    tf=\$(mktemp)
                    git show :\$f > \$tf
                    ./deploy/config/dynamic_config_util.rb validate --file="\$tf"
                    if [ \$? -ne 0 ]; then
                        echo "ERROR: EJSON file \$f validation failed" && { echo "ERROR: You have secrets not encrypted, run \"ejson encrypt ./deploy/config/*.ejson\" and try again"; exit 1; }
                    fi
                    rm -f \$tf
                done
            }
            function validate_test_file() {
                FILE=deploy/config/test
                if test -f "\$FILE"; then
                    if [[ -z \$(grep '[^[:space:]]' \$FILE) ]] ; then
                        echo "Empty file"
                    else
                        echo "\$FILE not Empty file please pull from falcon-prestaging"
                        exit 1
                    fi
                fi
            }
            validate_ejson
            validate_test_file
        """
    }
    println "encryption check completed :: " + getTimeStamp()
}

def sendEmail() {
    def jobName = currentBuild.fullDisplayName
    def authorLogin = params.ghprbPullAuthorLogin
    def authorEmail = params.ghprbPullAuthorEmail
    def pullTitle = params.ghprbPullTitle
    def pullLink = params.ghprbPullLink
    def pullId = params.ghprbPullId
    def jobUrl = env.BUILD_URL
    def mailRecipients = authorEmail + ", cc:freshdesk-tech-leads@freshworks.com, bcc:mahendran.kumaraguru@freshworks.com, bcc:nagarajan.raman@freshworks.com, bcc:navin.muthuswamy@freshworks.com"

    emailext body: "Build Failed on PR <a href=${pullLink}>#${pullId}</a> <strong>$pullTitle <br/><br/>Author:</strong> $authorLogin<br/><br/><strong>Job URL:</strong> $jobUrl",
        mimeType: 'text/html',
        subject: "[Jenkins] Falcon-Backend Unit Test Build Failed - #${env.BUILD_NUMBER}",
        to: "${mailRecipients}",
        replyTo: "${mailRecipients}"
}
